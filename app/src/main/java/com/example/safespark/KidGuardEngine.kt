package com.example.safespark

import android.content.Context
import android.util.Log
import com.example.safespark.ml.MLGroomingDetector
import com.example.safespark.ml.TrigramDetector
import com.example.safespark.ml.TimeInvestmentTracker
import com.example.safespark.ml.AdultChildDetector
import com.example.safespark.ml.ContextAwareDetector
import com.example.safespark.ml.StageProgressionDetector
import com.example.safespark.ml.OspreyLocalDetector
import com.example.safespark.ml.ConversationBuffer
import com.example.safespark.detection.SemanticDetector
import com.example.safespark.model.GroomingIntent
import com.example.safespark.logging.DetectionLogger
import com.example.safespark.logging.DetectionLogger.GroomingStage
import com.example.safespark.config.DetectionConfig
import com.example.safespark.trust.ContactTrustManager
import com.example.safespark.trust.TrustLevel
import kotlinx.coroutines.CoroutineScope
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.launch
import java.io.BufferedReader
import java.io.InputStreamReader
import java.io.Closeable

/**
 * Ergebnis der Text-Analyse mit Erkl√§rung (Explainable AI)
 * Basierend auf Basani et al. 2025 Paper
 */
data class AnalysisResult(
    val score: Float,
    val isRisk: Boolean,
    val explanation: String,
    val detectionMethod: String,
    val detectedPatterns: List<String> = emptyList(),
    val stage: String = "UNKNOWN",
    val confidence: Float = 0f,
    val allStageScores: Map<String, Float> = emptyMap()
)

/**
 * SafeSpark Engine f√ºr Text-Analyse
 *
 * Hybrid-System: Kombiniert 9 Detection-Layers:
 * 0. Semantic Similarity (NEU! - ERSTE PRIORIT√ÑT)
 * 1. Osprey Transformer (On-Device BERT/RoBERTa - 6 Grooming-Stages)
 * 2. ML-Modell (90.5% Accuracy)
 * 3. Trigram-Detection (+3% Accuracy)
 * 4. Time Investment Tracking (+2% Accuracy)
 * 5. Stage Progression Detection (+1% Accuracy)
 * 6. Adult/Child Context
 * 7. Context-Aware Detection
 * 8. Keyword-Matching (Fallback)
 *
 * GESAMT: ~95% Accuracy mit Semantic + Osprey Layer!
 */
class KidGuardEngine(private val context: Context) : Closeable {

    private val riskKeywords: Set<String>
    private val mlDetector: MLGroomingDetector
    private val trigramDetector: TrigramDetector
    private val timeTracker: TimeInvestmentTracker
    private val adultChildDetector: AdultChildDetector
    private val contextDetector: ContextAwareDetector
    private val stageDetector: StageProgressionDetector
    private val semanticDetector: SemanticDetector?  // Nullable f√ºr Fallback
    private val ospreyDetector: OspreyLocalDetector?  // Nullable falls Modell nicht verf√ºgbar
    private val TAG = "SafeSparkEngine"

    // Stage History f√ºr Progression-Tracking
    private val stageHistory = mutableListOf<StageProgressionDetector.StageEvent>()

    init {
        try {
            // Lade Risk Keywords aus Vocabulary
            riskKeywords = loadRiskKeywords(context)
            Log.d(TAG, "‚úÖ Engine initialisiert mit ${riskKeywords.size} Risk-Keywords")

            // Initialisiere alle Detektoren
            mlDetector = MLGroomingDetector(context)
            trigramDetector = TrigramDetector()
            timeTracker = TimeInvestmentTracker()
            adultChildDetector = AdultChildDetector()
            contextDetector = ContextAwareDetector()
            stageDetector = StageProgressionDetector()

            // Initialisiere Semantic Detector (mit Fallback)
            semanticDetector = try {
                SemanticDetector(context).also {
                    Log.d(TAG, "‚úÖ Semantic Detector initialisiert (H√ñCHSTE PRIORIT√ÑT)")
                }
            } catch (e: Exception) {
                Log.w(TAG, "‚ö†Ô∏è Semantic Detector konnte nicht geladen werden, nutze Fallback", e)
                null
            }

            // Initialisiere Osprey Detector (mit Fallback)
            ospreyDetector = try {
                OspreyLocalDetector(context).also {
                    Log.d(TAG, "‚úÖ Osprey Transformer-Detector initialisiert (6 Stages)")
                }
            } catch (e: Exception) {
                Log.w(TAG, "‚ö†Ô∏è Osprey Detector nicht verf√ºgbar (Modell fehlt)", e)
                null
            }

            Log.d(TAG, "‚úÖ ML-Detector initialisiert (90.5% Accuracy)")
            Log.d(TAG, "‚úÖ Trigram-Detector initialisiert (+3% Accuracy)")
            Log.d(TAG, "‚úÖ Time Investment Tracker initialisiert (+2% Accuracy)")
            Log.d(TAG, "‚úÖ Stage Progression Detector initialisiert (+1% Accuracy)")
            Log.d(TAG, "‚úÖ Adult/Child Detector initialisiert")
            Log.d(TAG, "‚úÖ Context-Aware Detector initialisiert")

            val totalLayers = 7 + (if (semanticDetector != null) 1 else 0) + (if (ospreyDetector != null) 1 else 0)
            val estimatedAccuracy = 90 + (if (semanticDetector != null) 3 else 0) + (if (ospreyDetector != null) 2 else 0)
            Log.d(TAG, "üéØ GESAMT: $totalLayers Detection-Layers, ~$estimatedAccuracy% Accuracy erreicht!")
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Fehler beim Initialisieren der Engine", e)
            throw RuntimeException("Fehler beim Initialisieren des SafeSparkEngine", e)
        }
    }
    
    /**
     * Analysiert einen Text und gibt einen Sicherheits-Score zur√ºck
     * 
     * Hybrid-Ansatz mit 7 Detection-Layers:
     * 1. ML-Modell (90.5% Accuracy)
     * 2. Trigram-Detection (+3%)
     * 3. Adult/Child Context Detection
     * 4. Context-Aware Detection
     * 5. Stage Progression Tracking (+1%)
     * 6. Assessment Pattern Matching
     * 7. Keyword-Matching (Fallback)
     *
     * @param input Der zu analysierende Text
     * @param appPackage Package-Name der Quell-App (f√ºr Context-Aware Detection)
     * @return Score zwischen 0.0 und 1.0, wobei h√∂here Werte auf riskanten Content hinweisen
     */
    /**
     * Analysiert einen Text und gibt einen Risk-Score (0.0-1.0) zur√ºck
     * 
     * @deprecated Use analyzeTextWithExplanation() or analyzeWithConversation() instead
     * @param input Der zu analysierende Text
     * @param appPackage Die App, aus der der Text stammt
     * @return Risk-Score (0.0 = safe, 1.0 = high risk)
     */
    @Deprecated("Use analyzeTextWithExplanation() or analyzeWithConversation() instead", 
        ReplaceWith("analyzeTextWithExplanation(input, appPackage).score"))
    fun analyzeText(input: String, appPackage: String = "unknown"): Float {
        return analyzeTextWithExplanation(input, appPackage).score
    }

    /**
     * Analysiert Text mit Erkl√§rung (Explainable AI)
     * Basierend auf Basani et al. 2025 Paper
     *
     * Detection-Reihenfolge:
     * 0. Semantic Similarity (NEU! - H√ñCHSTE PRIORIT√ÑT)
     * 1. Assessment-Pattern Check
     * 2. ML-Modell + weitere Detektoren
     *
     * Fix 3: Added additionalScores parameter for conversation-level scores
     *
     * @param input Der zu analysierende Text
     * @param appPackage Package-Name der Quell-App
     * @param additionalScores Additional scores from conversation-level analysis (e.g., OspreyConversation)
     * @return AnalysisResult mit Score und Erkl√§rung
     */
    fun analyzeTextWithExplanation(
        input: String, 
        appPackage: String = "unknown",
        additionalScores: Map<String, Float> = emptyMap()
    ): AnalysisResult {
        if (input.isBlank()) {
            return AnalysisResult(
                score = 0.0f,
                isRisk = false,
                explanation = "Leerer Text",
                detectionMethod = "None"
            )
        }

        // TEXT-LENGTH GATE: Skip short texts
        if (input.trim().length < DetectionConfig.MIN_TEXT_LENGTH) {
            Log.d(TAG, "‚è≠Ô∏è Text zu kurz (${input.trim().length} < ${DetectionConfig.MIN_TEXT_LENGTH}), safe result")
            return AnalysisResult(
                score = 0.0f,
                isRisk = false,
                explanation = "Text zu kurz f√ºr Analyse",
                detectionMethod = "TextLengthGate"
            )
        }

        // WORD COUNT GATE: Skip texts with too few words
        val wordCount = input.trim().split(Regex("\\s+")).filter { it.isNotEmpty() }.size
        if (wordCount < DetectionConfig.MIN_WORDS_FOR_PATTERN) {
            Log.d(TAG, "‚è≠Ô∏è Zu wenig W√∂rter ($wordCount < ${DetectionConfig.MIN_WORDS_FOR_PATTERN}), safe result")
            return AnalysisResult(
                score = 0.0f,
                isRisk = false,
                explanation = "Zu wenig W√∂rter f√ºr Musteranalyse",
                detectionMethod = "WordCountGate"
            )
        }

        val scores = mutableMapOf<String, Float>()
        // Fix 3: Merge additionalScores at the start
        scores.putAll(additionalScores)
        
        val detectedPatterns = mutableListOf<String>()
        var detectionMethod = "Unknown"
        var explanation = ""

        // CHECK FOR BYPASS PATTERNS FIRST (these trigger immediately!)
        if (DetectionConfig.matchesBypassPattern(input)) {
            Log.w(TAG, "üö® BYPASS PATTERN detected - immediate alert!")
            // Find which bypass pattern matched
            val matchedPattern = DetectionConfig.BYPASS_PATTERNS.find { 
                input.lowercase().contains(it) 
            } ?: "bypass pattern"
            
            DetectionLogger.logFinding(
                text = input,
                score = 0.95f,
                stage = GroomingStage.ISOLATION,
                method = "BypassPattern",
                pattern = matchedPattern
            )
            
            return AnalysisResult(
                score = 0.95f,
                isRisk = true,
                explanation = "üö® Kritisches Grooming-Muster erkannt: \"$matchedPattern\"",
                detectionMethod = "BypassPattern",
                detectedPatterns = listOf(matchedPattern),
                stage = "STAGE_ISOLATION",
                confidence = 0.95f
            )
        }

        // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        // 0. SEMANTIC SIMILARITY CHECK (collect score, no early return)
        // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        semanticDetector?.let { detector ->
            try {
                val semanticResult = detector.detectIntent(input)

                // Collect semantic score instead of early return
                if (semanticResult.isRisk && semanticResult.intent != null) {
                    scores["Semantic"] = semanticResult.similarity
                    semanticResult.matchedSeed?.let { detectedPatterns.add(it) }
                    detectionMethod = "Semantic-${semanticResult.intent}"
                    
                    val intent = semanticResult.intent
                    val stage = GroomingIntent.getStage(intent)
                    val intentExplanation = GroomingIntent.getExplanation(intent)
                    explanation = "üîç Semantische Erkennung: $intentExplanation\n\n" +
                                 "√Ñhnlich zu: \"${semanticResult.matchedSeed}\"\n" +
                                 "√Ñhnlichkeit: ${(semanticResult.similarity*100).toInt()}%"
                }

                // Log semantic scores auch bei no-match
                Log.d(TAG, "   Semantic Scores: ${semanticResult.allIntentScores.map { 
                    "${it.key}=${(it.value*100).toInt()}%" 
                }.joinToString(", ")}")

            } catch (e: Exception) {
                Log.w(TAG, "‚ö†Ô∏è Semantic detection failed, using fallback", e)
            }
        }

        // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        // 1. OSPREY TRANSFORMER CHECK (collect score, no early return)
        // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        ospreyDetector?.let { detector ->
            try {
                val ospreyResult = detector.predict(input)

                if (ospreyResult != null && ospreyResult.isRisk) {
                    scores["Osprey"] = ospreyResult.confidence
                    detectedPatterns.add(ospreyResult.stage)
                    if (detectionMethod == "Unknown") {
                        detectionMethod = "Osprey-${ospreyResult.stage}"
                        explanation = "ü§ñ Osprey Transformer: ${ospreyResult.explanation}"
                    }
                }

                // Log Osprey scores auch bei no-risk
                Log.d(TAG, "   Osprey Scores: ${ospreyResult?.allStageScores?.map { 
                    "${it.key}=${(it.value*100).toInt()}%" 
                }?.joinToString(", ") ?: "N/A"}")

            } catch (e: Exception) {
                Log.w(TAG, "‚ö†Ô∏è Osprey detection failed, using fallback", e)
            }
        }

        // 2. Assessment-Pattern Check (collect score, no early return unless bypass pattern)
        val lowerInput = input.lowercase().trim()

        // NEGATIONS-CHECK zuerst
        if (!DetectionConfig.containsNegation(input)) {
            val assessmentPatterns = mapOf(
                // Isolation/Assessment - PHRASEN (keep only clearly suspicious patterns)
                "bist du allein" to 0.85f,
                "bist du alleine" to 0.85f,
                "bist du gerade allein" to 0.90f,
                "are you alone" to 0.85f,
                "are you home alone" to 0.90f,
                "ist jemand bei dir" to 0.80f,
                "is anyone there" to 0.80f,
                "wo sind deine eltern" to 0.80f,
                "where are your parents" to 0.80f,
                "ist niemand da" to 0.85f,
                "bist du in deinem zimmer" to 0.75f,

                // Gift Giving - Only clearly suspicious patterns (removed ambiguous everyday phrases)
                // Removed: "ich kaufe dir", "ich schenke dir", "ich lade dich ein", "brauchst du geld"
                "ich schicke dir geld" to 0.85f,
                "ich schick dir geld" to 0.85f,
                "ich gebe dir geld" to 0.85f,
                "ich geb dir geld" to 0.85f,
                "ich √ºberweise dir" to 0.85f,
                "i'll send you money" to 0.85f,
                "i'll give you money" to 0.85f
            )

        for ((pattern, riskScore) in assessmentPatterns) {
            if (lowerInput.contains(pattern)) {
                // Collect score instead of early return
                scores["Assessment"] = riskScore
                detectedPatterns.add(pattern)
                if (detectionMethod == "Unknown") {
                    detectionMethod = "Assessment-Pattern"
                    explanation = "Erkannt wegen: '$pattern' (Assessment-Phase - kritisches Grooming-Muster)"
                }
                break  // Only match first pattern
            }
        }
        }

        // 2. ML-Prediction
        var detectedStage = "UNKNOWN"
        val mlPrediction = mlDetector.predict(input)
        if (mlPrediction != null && mlPrediction.isDangerous) {
            scores["ML"] = mlPrediction.confidence
            detectedPatterns.add("ML: ${mlPrediction.stage}")
            detectedStage = mlPrediction.stage  // Stage vom ML √ºbernehmen!
            if (mlPrediction.confidence > 0.7f) {
                detectionMethod = "Machine Learning"
                explanation = "ML-Modell erkannte: ${mlPrediction.stage}-Phase (${(mlPrediction.confidence * 100).toInt()}% Konfidenz)"
            }
        }

        // 3. Trigram Detection - Check both DE and EN
        val trigramResultDE = trigramDetector.detectTrigrams(input, "de")
        val trigramResultEN = trigramDetector.detectTrigrams(input, "en")
        val trigramResult = if (trigramResultDE.risk >= trigramResultEN.risk) trigramResultDE else trigramResultEN
        if (trigramResult.risk > 0.6f) {
            scores["Trigram"] = trigramResult.risk
            detectedPatterns.add("Trigram-Muster")
            if (detectionMethod == "Unknown") {
                detectionMethod = "Trigram-Analysis"
                explanation = "Verd√§chtige Wort-Kombinationen erkannt (${(trigramResult.risk * 100).toInt()}%)"
            }
        }

        // 4. Adult/Child Context
        val adultChildResult = adultChildDetector.analyzeMessage(input)
        if (adultChildResult.isLikelyAdult && adultChildResult.adultScore > 0.7f) {
            scores["AdultContext"] = adultChildResult.adultScore * 0.8f
            detectedPatterns.add("Erwachsenen-Sprache")
            if (detectionMethod == "Unknown") {
                detectionMethod = "Adult-Context"
                explanation = "Erwachsenen-typische Sprache erkannt (${(adultChildResult.adultScore * 100).toInt()}%)"
            }
        }

        // 5. Apply confidence adjustment by length to all scores
        val adjustedScores = scores.mapValues { (_, score) ->
            DetectionConfig.adjustConfidenceByLength(score, input.length)
        }.toMutableMap()

        // Log adjustments if text is short
        if (input.length < 30) {
            Log.d(TAG, "üìè Length adjustment applied (text length: ${input.length})")
            adjustedScores.forEach { (key, value) ->
                Log.d(TAG, "   $key: ${(scores[key]!!*100).toInt()}% ‚Üí ${(value*100).toInt()}%")
            }
        }

        // 6. Check for layer agreement (dual-confirmation)
        if (!DetectionConfig.hasLayerAgreement(adjustedScores)) {
            Log.d(TAG, "‚ö†Ô∏è Insufficient layer agreement - returning safe result")
            return AnalysisResult(
                score = 0.0f,
                isRisk = false,
                explanation = "Unzureichende Best√§tigung durch mehrere Layer",
                detectionMethod = "InsufficientAgreement",
                detectedPatterns = detectedPatterns,
                stage = detectedStage,
                confidence = 0.0f
            )
        }

        // 7. Berechne finalen Score
        val finalScore = if (adjustedScores.isEmpty()) 0.0f else calculateWeightedScore(adjustedScores)

        // 8. Generiere Erkl√§rung falls noch nicht vorhanden
        if (explanation.isEmpty()) {
            if (finalScore > 0.5f) {
                explanation = "Kombinierte Erkennung: ${detectedPatterns.joinToString(", ")}"
                detectionMethod = "Multi-Layer"

                // üö® STRUCTURED FINDING LOG f√ºr Multi-Layer Detection
                DetectionLogger.logFinding(
                    text = input,
                    score = finalScore,
                    stage = GroomingStage.UNKNOWN,
                    method = "Multi-Layer",
                    pattern = detectedPatterns.firstOrNull()
                )
            } else {
                explanation = "Keine verd√§chtigen Muster erkannt"
                detectionMethod = "Safe"
            }
        }

        return AnalysisResult(
            score = finalScore,
            isRisk = finalScore > 0.5f,
            explanation = explanation,
            detectionMethod = detectionMethod,
            detectedPatterns = detectedPatterns,
            stage = detectedStage,
            confidence = finalScore
        )
    }

    /**
     * Berechnet gewichteten Score aus allen Detection-Layers
     *
     * Basierend auf Papers: Frontiers Pediatrics, ArXiv 2409.07958v1
     * 
     * Fix 3: Added OspreyConversation layer and rebalanced weights
     */
    private fun calculateWeightedScore(scores: Map<String, Float>): Float {
        if (scores.isEmpty()) return 0.0f

        // üîç ULTRA-DEBUG: Zeige ALLE Scores
        Log.e(TAG, "‚îÅ‚îÅ‚îÅ calculateWeightedScore START ‚îÅ‚îÅ‚îÅ")
        scores.forEach { (key, value) ->
            Log.e(TAG, "  $key = ${(value*100).toInt()}%")
        }

        // Log Assessment, StageProgression, and AdultContext scores for debugging
        val assessmentScore = scores["Assessment"] ?: 0.0f
        Log.e(TAG, "  Assessment-Check: ${(assessmentScore*100).toInt()}%")
        
        val stageProgressionScore = scores["StageProgression"] ?: 0.0f
        if (stageProgressionScore > 0.7f) {
            Log.w(TAG, "  Stage-Anomalie erkannt! Score: ${(stageProgressionScore*100).toInt()}%")
        }
        
        val adultContextScore = scores["AdultContext"] ?: 0.0f
        if (adultContextScore > 0.7f) {
            Log.w(TAG, "  Adult-Context (potentieller Groomer) erkannt! Score: ${(adultContextScore*100).toInt()}%")
        }

        // Fix 3: Gewichte pro Detection-Layer (rebalanced with OspreyConversation)
        val weights = mapOf(
            "Semantic" to 0.22f,              // Semantic: 22% (was 25%)
            "OspreyConversation" to 0.18f,    // Osprey Conversation: 18% (NEW!)
            "Osprey" to 0.15f,                // Osprey Transformer: 15% (was 20%)
            "ML" to 0.18f,                    // ML-Modell: 18% (was 20%)
            "Trigram" to 0.10f,               // Trigrams: 10% (was 12%)
            "AdultContext" to 0.08f,          // Adult Context: 8% (was 10%)
            "Context" to 0.05f,               // Context-Aware: 5% (was 8%)
            "StageProgression" to 0.02f,      // Stage Progression: 2% (was 3%)
            "Assessment" to 0.12f,            // Assessment Patterns: 12% (was 15%)
            "Keywords" to 0.01f               // Keywords: 1% (unchanged)
        )

        var weightedSum = 0.0f
        var totalWeight = 0.0f

        scores.forEach { (key, score) ->
            if (score > 0.0f) {  // ‚Üê Nur non-zero Scores z√§hlen!
                val weight = weights[key] ?: 0.0f
                weightedSum += score * weight
                totalWeight += weight
            }
        }

        // Normalisiere auf vorhandene Weights
        return if (totalWeight > 0) {
            (weightedSum / totalWeight).coerceIn(0.0f, 1.0f)
        } else {
            0.0f
        }
    }

    /**
     * Analysiert eine Conversation mit Time Investment Tracking
     *
     * @param messages Liste von Messages mit Timestamps
     * @return Erweiterte Risk-Analyse
     */
    fun analyzeConversation(
        messages: List<Pair<String, Long>>  // (Text, Timestamp)
    ): ConversationAnalysis {
        if (messages.isEmpty()) {
            return ConversationAnalysis(0.0f, emptyList(), null)
        }

        // Analysiere einzelne Messages
        val messageScores = messages.map { (text, _) -> analyzeText(text) }
        val avgMessageScore = messageScores.average().toFloat()

        // Time Investment Analysis
        val firstTime = messages.first().second
        val lastTime = messages.last().second
        val timeMetrics = timeTracker.analyzeConversation(
            messageCount = messages.size,
            firstMessageTime = firstTime,
            lastMessageTime = lastTime
        )

        // Kombiniere Message-Scores + Time Investment
        val timeBoost = timeMetrics.timeInvestmentScore * 0.2f // +20% bei hohem Investment
        val finalScore = (avgMessageScore + timeBoost).coerceIn(0.0f, 1.0f)

        Log.d(TAG, "üí¨ Conversation Analysis: ${messages.size} messages, Score: ${(finalScore*100).toInt()}%")
        Log.d(TAG, "   Time Investment: ${(timeMetrics.timeInvestmentScore*100).toInt()}%, Speed: ${timeMetrics.progressionSpeed}")

        return ConversationAnalysis(
            overallRisk = finalScore,
            messageScores = messageScores,
            timeMetrics = timeMetrics
        )
    }

    data class ConversationAnalysis(
        val overallRisk: Float,
        val messageScores: List<Float>,
        val timeMetrics: TimeInvestmentTracker.ConversationMetrics?
    )

    /**
     * L√§dt Risk-Keywords aus der Vocabulary-Datei
     */
    private fun loadRiskKeywords(context: Context): Set<String> {
        val keywords = mutableSetOf<String>()

        try {
            context.assets.open("vocabulary.txt").use { inputStream ->
                BufferedReader(InputStreamReader(inputStream, Charsets.UTF_8)).use { reader ->
                    // Skip h√§ufige W√∂rter die keine Risk sind
                    val skipWords = setOf(
                        "<unk>", "the", "to", "and", "a", "of", "is", "in",
                        "you", "it", "that", "child", "safety", "protect"
                    )

                    reader.forEachLine { line ->
                        val word = line.trim().lowercase()
                        if (word.isNotEmpty() && !skipWords.contains(word)) {
                            keywords.add(word)
                        }
                    }
                }
            }
            Log.d(TAG, "‚úÖ ${keywords.size} Risk-Keywords aus Vocabulary geladen")
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Fehler beim Laden des Vocabulary", e)
            return setOf()
        }
        
        return keywords
    }
    
    /**
     * Analysiert Text mit Konversationskontext
     *
     * Nutzt den ConversationBuffer um Nachrichten pro Kontakt zu sammeln
     * und erm√∂glicht Osprey, Eskalationsmuster √ºber den Verlauf zu erkennen.
     *
     * @param input Der zu analysierende Text
     * @param appPackage Package-Name der Quell-App
     * @param chatIdentifier Chat-Fenster-Titel oder √§hnliches (wird pseudonymisiert)
     * @param isLocalUser true wenn die Nachricht vom Kind stammt, false wenn vom Kontakt
     * @return AnalysisResult mit Score und Erkl√§rung
     */
    fun analyzeWithConversation(
        input: String,
        appPackage: String = "unknown",
        chatIdentifier: String = "default",
        isLocalUser: Boolean = false
    ): AnalysisResult {
        if (input.isBlank()) {
            return AnalysisResult(
                score = 0.0f,
                isRisk = false,
                explanation = "Leerer Text",
                detectionMethod = "None"
            )
        }

        // TEXT-LENGTH GATE: Skip short texts (same as analyzeTextWithExplanation)
        if (input.trim().length < DetectionConfig.MIN_TEXT_LENGTH) {
            Log.d(TAG, "‚è≠Ô∏è Text zu kurz (${input.trim().length} < ${DetectionConfig.MIN_TEXT_LENGTH}), skipping")
            return AnalysisResult(
                score = 0.0f,
                isRisk = false,
                explanation = "Text zu kurz f√ºr Analyse",
                detectionMethod = "Skipped"
            )
        }

        // WORD COUNT GATE: Skip texts with too few words
        val wordCount = input.trim().split(Regex("\\s+")).filter { it.isNotEmpty() }.size
        if (wordCount < DetectionConfig.MIN_WORDS_FOR_PATTERN) {
            Log.d(TAG, "‚è≠Ô∏è Zu wenig W√∂rter ($wordCount < ${DetectionConfig.MIN_WORDS_FOR_PATTERN}), skipping")
            return AnalysisResult(
                score = 0.0f,
                isRisk = false,
                explanation = "Zu wenig W√∂rter f√ºr Analyse",
                detectionMethod = "Skipped"
            )
        }

        // 1. Generiere pseudonymisierte Contact-ID
        val contactId = ConversationBuffer.generateContactId(appPackage, chatIdentifier)

        // 2. F√ºge Nachricht zum Buffer hinzu
        val message = ConversationBuffer.ConversationMessage(
            text = input,
            authorId = if (isLocalUser) "child" else contactId,
            timestamp = System.currentTimeMillis(),
            isLocalUser = isLocalUser
        )
        ConversationBuffer.addMessage(contactId, message)

        // 3. Hole Konversationskontext
        val conversation = ConversationBuffer.getConversation(contactId)
        val contextFeatures = ConversationBuffer.getContextFeatures(contactId)

        // Fix 3: Collect Osprey conversation score for feeding into multi-layer scoring
        val conversationScores = mutableMapOf<String, Float>()
        
        // 4. Analysiere mit Osprey auf Konversationsebene (wenn verf√ºgbar)
        ospreyDetector?.let { detector ->
            try {
                if (conversation.size >= 2) {
                    // Genug Kontext f√ºr Konversationsanalyse
                    val ospreyResult = detector.analyzeConversation(conversation, contextFeatures)

                    // Apply confidence adjustment by length before checking threshold
                    val adjustedConfidence = DetectionConfig.adjustConfidenceByLength(ospreyResult.confidence, input.length)

                    // Check that the Osprey confidence exceeds OSPREY_THRESHOLD
                    if (adjustedConfidence > DetectionConfig.OSPREY_THRESHOLD) {
                        Log.w(TAG, "‚ö†Ô∏è OSPREY CONVERSATION RISK: ${ospreyResult.stage} (${(adjustedConfidence*100).toInt()}%)")
                        
                        // Score wird als riskScore gespeichert, aber kein Sofort-Return
                        // F√§llt durch zum normalen Multi-Layer-Pfad (analyzeTextWithExplanation)
                        message.riskScore = adjustedConfidence
                        
                        // Fix 3: Collect score for multi-layer analysis
                        conversationScores["OspreyConversation"] = adjustedConfidence

                        // Logge Finding
                        DetectionLogger.logFinding(
                            text = input,
                            score = adjustedConfidence,
                            stage = GroomingStage.fromString(ospreyResult.stage),
                            method = "Osprey-Conversation",
                            pattern = ospreyResult.dominantProgression
                        )
                        // Sofort-Return ENTFERNT ‚Äì stattdessen durch den normalen Pfad laufen lassen
                    }
                }
            } catch (e: Exception) {
                Log.w(TAG, "‚ö†Ô∏è Osprey conversation analysis failed", e)
            }
        }

        // Fix 3: Pass conversation scores to analyzeTextWithExplanation
        var baseResult = analyzeTextWithExplanation(input, appPackage, conversationScores)
        
        // Fix 5: Apply safe-context boost if conversation history is suspicious
        val safeContextScore = ConversationBuffer.getSafeContextScore(contactId)
        if (safeContextScore < 0.3f && conversation.size >= 5) {
            val boostedScore = (baseResult.score + 0.1f).coerceIn(0f, 1f)
            Log.w(TAG, "üö® CONTEXT BOOST applied: ${(baseResult.score * 100).toInt()}% ‚Üí ${(boostedScore * 100).toInt()}% (safeContext: ${(safeContextScore * 100).toInt()}%)")
            baseResult = baseResult.copy(score = boostedScore, isRisk = boostedScore > 0.5f)
        }

        // Fix 1: Use sync cache lookup instead of runBlocking
        val trustLevel = ContactTrustManager.getTrustLevelSync(contactId)
        
        // Fix 1: Fire-and-forget async refresh (non-blocking)
        kotlinx.coroutines.CoroutineScope(kotlinx.coroutines.Dispatchers.IO).launch {
            try {
                ContactTrustManager.refreshTrustCache(contactId, context)
            } catch (e: Exception) {
                Log.w(TAG, "‚ö†Ô∏è Async trust cache refresh failed", e)
            }
        }

        val adjustedScore = ContactTrustManager.applyTrustModifier(baseResult.score, trustLevel, input)

        // Fix 1 & Fix 4: Fire-and-forget async stats update with RAW score (before trust modifier)
        kotlinx.coroutines.CoroutineScope(kotlinx.coroutines.Dispatchers.IO).launch {
            try {
                // Fix 4: Pass RAW baseResult.score for risk-spike detection
                ContactTrustManager.updateContactStats(contactId, baseResult.score, context)
            } catch (e: Exception) {
                Log.w(TAG, "‚ö†Ô∏è Async contact stats update failed", e)
            }
        }

        return if (adjustedScore != baseResult.score) {
            baseResult.copy(
                score = adjustedScore,
                isRisk = adjustedScore > 0.5f
            )
        } else {
            baseResult
        }
    }

    /**
     * Schlie√üt die Engine und gibt Ressourcen frei
     */
    override fun close() {
        // Buffer leeren (DSGVO)
        ConversationBuffer.clearAll()

        mlDetector.close()
        semanticDetector?.close()
        ospreyDetector?.close()
        Log.d(TAG, "üîí SafeSparkEngine geschlossen")
    }
}
