# ğŸš€ KidGuard ML Training - Phase 1 & 2

## ğŸ“‹ Ãœbersicht

Dieses Verzeichnis enthÃ¤lt alle Scripts fÃ¼r das Training eines **kontextbewussten TensorFlow Lite Modells < 5MB** fÃ¼r On-Device Risikoerkennung auf dem Pixel 10.

---

## ğŸ¯ Ziele

### Phase 1: Synthetische Basis-Daten
- **2000 Beispiele** generieren (Safe, Toxic, Grooming)
- **Keyword-Basis** Ã¼berwinden
- **Kontext-VerstÃ¤ndnis** aufbauen

### Phase 2: Sliding Window & Kontext
- **3-5 Nachrichten Fenster** fÃ¼r GesprÃ¤chsverlÃ¤ufe
- **Grooming-Pattern Erkennung** (Six Stages)
- **< 5MB Modell-GrÃ¶ÃŸe**
- **< 50ms Inferenz-Zeit** auf Pixel 10

---

## ğŸ“¦ Installation

### 1. Python Environment erstellen

```bash
cd /Users/knutludtmann/AndroidStudioProjects/KidGuard/ml

# Virtual Environment erstellen
python3 -m venv venv

# Aktivieren
source venv/bin/activate  # macOS/Linux
# oder
venv\Scripts\activate  # Windows

# Dependencies installieren
pip install tensorflow==2.14.0 numpy scikit-learn
```

---

## ğŸš€ Training DurchfÃ¼hren

### Schritt 1: Daten generieren

```bash
cd scripts
python generate_data.py
```

**Output:**
```
Generated 2000 examples
Saved to data/training_data.json
```

### Schritt 2: Modell trainieren

```bash
python train_model.py
```

**Expected Output:**
```
âœ… Keras Modell gespeichert: models/kidguard_model.h5
âœ… TFLite Modell gespeichert: models/kidguard_model.tflite
ğŸ“¦ GrÃ¶ÃŸe: 2.3 MB
â±ï¸  Inferenz-Zeit: 12.5 ms
âœ… Performance-Ziel erreicht (< 50ms)!
```

---

## ğŸ“‚ Output-Struktur

Nach dem Training:

```
ml/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ training_data.json          # Generierte Training-Daten
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ kidguard_model.tflite       # â­ FÃ¼r Android
â”‚   â”œâ”€â”€ vocabulary.json             # â­ FÃ¼r Android  
â”‚   â””â”€â”€ kidguard_model.h5           # Keras Backup
â””â”€â”€ scripts/
    â”œâ”€â”€ generate_data.py            # Datengenerierung
    â””â”€â”€ train_model.py              # Modell Training
```

---

## ğŸ“± Android Integration

### Schritt 1: Assets kopieren

```bash
# Kopiere Modell und Vokabular
cp models/kidguard_model.tflite ../app/src/main/assets/
cp models/vocabulary.json ../app/src/main/assets/
```

### Schritt 2: MLRiskAnalyzer implementieren

Siehe: `ML_INTEGRATION_GUIDE.md`

---

## ğŸ§ª Testing

### Test-Beispiele

```python
test_texts = [
    "Hey wie geht's?",              # â†’ Safe
    "Du bist so dumm",              # â†’ Toxic
    "Das bleibt unser Geheimnis",   # â†’ Grooming
    "Schick mir ein Bild",          # â†’ Grooming
    "Hast du Hausaufgaben?",        # â†’ Safe
]
```

### Performance-Ziele

- âœ… **Modell-GrÃ¶ÃŸe:** < 5 MB
- âœ… **Inferenz-Zeit:** < 50 ms
- âœ… **Accuracy:** > 85%
- âœ… **False Positives:** < 10%

---

## ğŸ”„ Training-Konfiguration

### Modell-Parameter

```python
CONFIG = {
    "max_words": 500,              # Vokabular-GrÃ¶ÃŸe
    "max_sequence_length": 30,     # Max WÃ¶rter pro Nachricht
    "embedding_dim": 16,           # Embedding-Dimension
    "context_window": 3,           # Sliding Window GrÃ¶ÃŸe
    "epochs": 50,
    "batch_size": 32,
    "num_classes": 3,              # Safe, Toxic, Grooming
}
```

### Architektur

```
Input (30 Tokens)
    â†“
Embedding (16D)
    â†“
Conv1D (32 Filters, Kernel=3)
    â†“
GlobalAveragePooling1D
    â†“
Dense (16 Units, ReLU)
    â†“
Dropout (0.5)
    â†“
Dense (3 Units, Softmax)
    â†“
Output [Safe, Toxic, Grooming]
```

**GesamtgrÃ¶ÃŸe:** ~2-3 MB (mit INT8 Quantization)

---

## ğŸ“Š Training-Daten Details

### Verteilung

- **40% Safe** (800 Beispiele)
  - Hausaufgaben, Gaming, Sport, Alltag
  
- **30% Toxic** (600 Beispiele)
  - Beleidigungen, Scam, Druck, Aggression
  
- **30% Grooming** (600 Beispiele)
  - Geheimnisse, Geschenke, Treffen, Sexualisierung

### Beispiele

**Safe:**
```json
{
  "text": "Hast du die Mathe-Hausaufgaben schon gemacht?",
  "label": 0,
  "category": "safe_hausaufgaben"
}
```

**Toxic:**
```json
{
  "text": "Du bist so dumm",
  "label": 1,
  "category": "toxic_beleidigung"
}
```

**Grooming:**
```json
{
  "text": "Das bleibt unser Geheimnis okay?",
  "label": 2,
  "category": "grooming_geheimnisse"
}
```

---

## ğŸ”§ Optimierungen

### Modell-GrÃ¶ÃŸe reduzieren

1. **Vokabular verkleinern:**
   ```python
   CONFIG["max_words"] = 300  # statt 500
   ```

2. **Embedding-Dimension reduzieren:**
   ```python
   CONFIG["embedding_dim"] = 12  # statt 16
   ```

3. **INT8 Quantization:**
   ```python
   converter.optimizations = [tf.lite.Optimize.DEFAULT]
   ```

### Performance verbessern

1. **Sequence-Length reduzieren:**
   ```python
   CONFIG["max_sequence_length"] = 20  # statt 30
   ```

2. **Conv1D statt LSTM:**
   - Schneller
   - Weniger Parameter
   - Besser fÃ¼r On-Device

---

## ğŸš¨ Troubleshooting

### Problem: Modell > 5MB

**LÃ¶sung:**
```python
# Reduziere Konfiguration
CONFIG["max_words"] = 300
CONFIG["embedding_dim"] = 12
```

### Problem: Inferenz > 50ms

**LÃ¶sung:**
```python
# Reduziere Sequence-Length
CONFIG["max_sequence_length"] = 20

# Nutze Conv1D statt LSTM
model = create_lightweight_model()  # nicht create_context_model()
```

### Problem: Zu viele False Positives

**LÃ¶sung:**
```bash
# Mehr Safe-Beispiele generieren
python generate_data.py --safe-ratio 0.5
```

---

## ğŸ“ˆ NÃ¤chste Schritte (Phase 3 & 4)

### Phase 3: BKA/LKA Daten

1. **Echte Protokolle analysieren**
2. **Hard Example Mining**
3. **Fine-Tuning des Modells**

### Phase 4: On-Device Test

1. **Performance-Messung auf Pixel 10**
2. **False-Positive Rate messen**
3. **Feedback-Loop implementieren**

---

## ğŸ“ Lizenz & Hinweise

âš ï¸ **Wichtig:**
- Training-Daten sind **synthetisch**
- FÃ¼r Produktions-Nutzung: **Echte Daten** (BKA/LKA) notwendig
- **Privacy-konform:** Alles On-Device, keine Cloud

---

## ğŸ“š Weitere Dokumentation

- `ML_INTEGRATION_GUIDE.md` - Android Integration
- `PERFORMANCE_TUNING.md` - Optimierungs-Tipps
- `DATASET_EXPANSION.md` - Mehr Training-Daten

---

**Erstellt:** 25. Januar 2026  
**Status:** Phase 1 & 2 implementiert  
**Ziel:** < 5MB, < 50ms, On-Device
